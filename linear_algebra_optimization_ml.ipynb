{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e239996",
   "metadata": {},
   "source": [
    "# Álgebra Linear e Otimização para Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845df84",
   "metadata": {},
   "source": [
    "Notas e resumos do estudo sobre álgebra linear e otimização focado em machine learning, baseado no livro \n",
    "_[Linear Algebra and Optimization for Machine Learning](https://doi.org/10.1007/978-3-030-40344-7)_ de Charu C. Aggarwal. Para facilitar a localização das notas, estou utilizando o sumário do livro nos tópicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e94297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T23:03:50.470421Z",
     "start_time": "2022-11-16T23:03:50.398423Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import latexify\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08290341",
   "metadata": {},
   "source": [
    "# Notações\n",
    "- Vetores ou data points multidimensionais serão representados pela notação com barra como $\\bar{X}$ ou $\\bar{y}$.\n",
    "- Os produtos entre vetores serão representandos com pontos centralizados $\\bar{X}$ ${\\cdot}$ $\\bar{Y}$.\n",
    "- Uma matrix será representada por uma letra maíscula sem barra, como R.\n",
    "- Matrizes n × d correspondem a todo o data set de treinamento, denotado por D, com n pontos de dados e d dimensões.\n",
    "- Os data points individuais em D são vetores linhas d-dimensionais e são denotados por $\\bar{X}$1... $\\bar{X}$n\n",
    "- Vetores com um componente para cada data point são vetores colunas n-dimensionais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75db4b2",
   "metadata": {},
   "source": [
    "# Álgebra Linear e Otimização: Uma Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfcd96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T19:53:39.326906Z",
     "start_time": "2022-11-14T19:53:39.321124Z"
    }
   },
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49ce7c8",
   "metadata": {},
   "source": [
    "- Modelos de machine learninig contrõem modelos matemáticos a partir dos dados, que contêm multiplos atributos ou variáveis. \n",
    "- O relacionamento entre o modelo e os dados são expressos de forma linear ou não linear.\n",
    "- Esses relacionamentos são descobertos de forma data driven otimizando (maximizando) o ajuste (\"agreement\") entre o modelo e os dados observados\n",
    "- Álgebra linear é o *estudo de operações lineares em espaços vetoriais*. Um espaço vetorial é o conjunto infinito de todas as coordenadas cartesianas em duas dimensões em relação a um ponto fixo, a origem. Álgebra linear pode ser vista como uma forma de generalização da geometria de coordenadas Cartesiana em d-dimensões.\n",
    "- Em machine learning, o conjunto de dados é representado com multiplas dimensões (atributos).\n",
    "- Uma prática comum é aplicar funções lineares a vetores com alta dimencionalidade para extrair suas propriedades analíticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540c739",
   "metadata": {},
   "source": [
    "## Scalars, Vetores e Matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddd665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T11:40:33.435515Z",
     "start_time": "2022-11-15T11:40:33.428005Z"
    }
   },
   "source": [
    "<img src=\"scalar-vector-matrix.jpg\">\n",
    "\n",
    "- Scalars: São valores numéricos individuais normalmente extraídos do domínio real em machine learning, como o atritubo \"idade\".\n",
    "\n",
    "- Vetores: São arrays de valores numéricos (arrays de escalares). Também são referidos como coordenadas. Os valores numéricos individuais dos arrays são chamados de entidades, componentes ou dimensões do vetor. E o número de componentes é referido como dimensionalidade do vetor. Um vetor de 3 dimensões de uma pessoa de 25 anos, fazendo 30 USD por hora e possuindo 5 anos de experiência é representado como um array com os números [25, 30, 5]\n",
    "\n",
    "- Matrizes: São arrays de números retangulares que contêm linhas e colunas. Para acessarmos o elemento na matriz, devemos especificar o índice da linha e o índice da coluna (i, j). O tamanho da matriz é denotada por n x d, sendo n o número de indivíduos e d o número de dimensões. Quando uma matriz possui o mesmo número de linhas e colunas, é chamada de square matrix ou matriz quadrada, nos demais casos de matriz retangular.\n",
    "\n",
    "- Por padrão, vetores são assumidos como vetores coluna em álgebra linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27282f32",
   "metadata": {},
   "source": [
    "### Operações Básicas com Scalars e Vetores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a521d31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T12:33:14.191627Z",
     "start_time": "2022-11-15T12:33:14.186862Z"
    }
   },
   "source": [
    "- Vetores de mesma dimensionalidade podem ser somados ou subtraídos.\n",
    "- Considerando dois vetor de d-dimensões $\\bar{x} = [x1... xd]$ e $\\bar{y} = [yi...yd]$, podem ser somados como \n",
    "\n",
    "<center> $\\bar{x} + \\bar{y}$ = $[xi...xd] + [yi...yd] = [x1 + y1... xd + yd]$ </center>\n",
    "\n",
    "assim como subtraídos da mesma forma \n",
    "\n",
    "<center> $\\bar{x} + \\bar{y} = [xi...xd] - [yi...yd] = [x1 - y1... xd - yd]$ </center>\n",
    "\n",
    "- A adição de vetores é comutativa (como adição escalar) porquê $\\bar{x}$ + $\\bar{y}$ = $\\bar{y}$ + $\\bar{x}$. A comutatividade da adição, ou simplesmente propriedade comutativa, diz para gente que a ordem da adição não importa, sempre chegaremos ao mesmo resultado. Ou seja, 2 + 3 é igual a 3 + 2, pois 3 + 2 é igual a 5, da mesma forma que 2 + 3 também é igual a 5.\n",
    "\n",
    "- É possível multiplicar um vetor com um escalar, multiplicando cada elemento do vetor com o escalar. Multiplicando o vetor $\\bar{x} = [x1... xd]$ escalado pelo fator de a\n",
    "\n",
    "<center> $\\bar{x}' = a\\bar{x} = [ax1...axd]$ </center>\n",
    "\n",
    "- Um comprimento (length) do vetor pode ser escalado, não alterando a sua direção com uma multiplicação escalar. Considere o vetor $\\bar{x}$ contendo o número de unidades vendidas de um produto, o número de unidades vendidas pode ser convertida em milhões de unidades vendidas ao multiplicar o vetor com a = 10⁻⁶.\n",
    "\n",
    "- Os vetores podem ser multiplicados com a noção do produto escalar (dot produt). **O produto escalar entre dois vetores é a soma da multiplicação elemento a elemento de seus componentes individuais.** \n",
    "\n",
    "<center> $\\bar{x} \\cdot \\bar{y} = \\sum_{i=1}^{d} xiyi $</center>\n",
    "\n",
    "- [inserir gif de multiplicação de matrizes]***\n",
    "\n",
    "- O produto escalar dos vetores $\\bar{x}$ = [1, 2, 3] e $\\bar{y}$ = [6, 5, 4] pode ser computado da seguinte forma:\n",
    "\n",
    "<center> $\\bar{x} \\cdot \\bar{y} = (1)(6) + (2)(5) + (3)(4) = 28$ </center> \n",
    "\n",
    "- O produto escalar é um caso especial de uma operação mais geral, chamada de produto interno, e preserva muitas regras fundamentais da geometria euclidiana. O espaço de vetores que inclui uma operação de produto escalar é chamado de espaço euclidiano. O produto escalar é uma operação comutativa\n",
    "\n",
    "<center> $\\bar{x} \\cdot \\bar{y} = \\sum_{i=1}^{d} xiyi = \\sum_{i=1}^{d}yixi = \\bar{y} \\cdot \\bar{x}$</center>\n",
    "\n",
    "- O produto escalar também herda as propriedades distributivas da multiplicação escalar. A propriedade distributiva é utilizada quando um número está multiplicando uma adição ou subtração. Basta multiplicar separado cada termo e, somar ou subtrair o resultado. Nós distribuímos a multiplicação do 2, para o 8 e para o 3. Uma dica importante é colocar em evidência.\n",
    "\n",
    "<center>$\\bar{x} \\cdot (\\bar{y}+\\bar{z}) = \\bar{x} \\cdot \\bar{y} + \\bar{x} \\cdot \\bar{z}$</center>\n",
    "\n",
    "- O produto escalar de um vetor $\\bar{x} = [x1... xd]$ com ele mesmo é chamado **norma quadrada (squared norm)** ou [**norma Euclidiana**](https://www.youtube.com/watch?v=41XmlK7itG8). Essa norma define o comprimento do vetor e é denotado por $||\\cdot||$\n",
    "\n",
    "<center> $||\\bar{x}||^{2} = \\bar{x} \\cdot \\bar{x} = \\sum_{i=1}^{d}x_{i}^{2} $ </center>\n",
    "\n",
    "- **A norma de um vetor é a distância** Euclidiana de suas coordenadas a partir de sua origem. Frequentemente os vetores são normalizados para o comprimento unitário dividindo eles pela sua norma\n",
    "\n",
    "<center> $$\\bar{x}' = \\frac{\\bar{x}}{||\\bar{x}||} = \\frac{\\bar{x}}{\\sqrt{\\bar{x} \\cdot \\bar{x}}}$$ </center>\n",
    "\n",
    "- Dimensionar (scaling) um vetor por sua norma não altera os valores relativos de seus componentes, que definem a direção do vetor. Por exemplo, a distância euclidiana de [4, 3] da origem é 5. A divisão de cada componente do vetor por 5 resulta no vetor [4/5, 3/5], que altera o comprimento do vetor para 1, mas não sua direção. O vetor resultante é chamado de vetor unitário.\n",
    "\n",
    "Uma generalização da norma Euclidiana é a $L_{p}-norm$, que é denotada por $||\\cdot||_{p}$:\n",
    "\n",
    "<center> $ ||\\bar{x}||_{p} = (\\sum_{i=1}^{d}|xi|^{p})^{(1/p)} $ </center>\n",
    "\n",
    "Aqui, $|\\cdot|$ indica o valoe absoluto do escalar, e o p é um inteiro positivo. Por exemplo, quando p é definido como 1, a norma resultante é referida como norma Manhattan ou $L_{1}-norm\n",
    "\n",
    "- A distância Euclidiana quadrada entre $\\bar{x} = [x1,... xd]$ e $\\bar{y} = [y1,... yd]$ pode ser mostrada pelo produto escalar de $\\bar{x}-\\bar{y}$ com ele mesmo, como:\n",
    "\n",
    "<center> $ ||\\bar{x}-\\bar{y}||^{2} = (\\bar{x}-\\bar{y}) \\cdot (\\bar{x}-\\bar{y}) = \\sum_{i=1}^{d}(xi-yi)^{2} = Euclidian(\\bar{x}, \\bar{y})^{2} $ </center>\n",
    "\n",
    "- Produtos escalares satisfazem a [desigualdade de Cauchy-Schwarz](https://pt.wikipedia.org/wiki/Desigualdade_de_Cauchy-Schwarz), segundo a qual o produto escalar entre um par de vetores é limitado acima pelo produto de seus comprimentos\n",
    "\n",
    "<center> $ |\\sum_{i=1}^{d}xiyi = |\\bar{x}\\cdot\\bar{y}| \\leq ||\\bar{x}||  ||\\bar{y}|| $</center>\n",
    "\n",
    "- A desigualdade de Cauchy-Schwarz mostra que **o produto escalar entre um par de vetores não é maior que o produto dos comprimentos dos vetores**. A desigualdade de Cauchy-Schwarz pode ser provada promeiro mostrando que $|\\bar{x}\\cdot\\bar{y}| \\leq 1$ quando $\\bar{x}$ e $\\bar{y}$ são vetores unitários, ou seja, o resultado é válido quando so argumentos são vetores unitários. Isso porquê ambos $||\\bar{x}-\\bar{y}||^{2} = 2-2\\bar{x}\\cdot\\bar{y}$ e $||\\bar{x}+\\bar{y}||^{2} = 2+2\\bar{x}\\cdot\\bar{y}$ são não negativos. Isso é possível quando $|\\bar{x}\\cdot\\bar{y}| \\leq 1$. Pode-se então generalizar esse resultado para vetores de comprimento arbitrário observando que o produto escalar aumenta linearmente com as normas dos argumentos subjacentes. Portanto, pode-se escalar ambos os lados da desigualdade com as normas dos vetores.\n",
    "\n",
    "Exemplos:\n",
    "- [Desigualdade de Cauchy-Schwarz](https://www.youtube.com/watch?v=cuq5om9TAPQ)\n",
    "- [Desigualdade de Cauchy-Schwarz](https://www.youtube.com/watch?v=IxxIyceUAXA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2a44a",
   "metadata": {},
   "source": [
    "### Operações Básicas com Vetores e Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26354cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# matriz em latex\n",
    "# https://www.overleaf.com/learn/latex/Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc467dd",
   "metadata": {},
   "source": [
    "### Classes Especiais de Matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad390a",
   "metadata": {},
   "source": [
    "### Potência de Matrizes, Polinomiais e Inversas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773c7420",
   "metadata": {},
   "source": [
    "### Inversão Lemma de Matrizes: Invertendo a Soma de Matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce5259",
   "metadata": {},
   "source": [
    "### Norma de Frobenius, Trace e Energia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63def52",
   "metadata": {},
   "source": [
    "## Multiplicação de Matrizes como Decomposable Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e74be4",
   "metadata": {},
   "source": [
    "### Multiplicação de MAtrizes como Decomposable Row e Column Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b29625",
   "metadata": {},
   "source": [
    "### Multiplicação de MAtrizes como Decomposable Geometric Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5397dc",
   "metadata": {},
   "source": [
    "## Problemas Básicos em Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aae58",
   "metadata": {},
   "source": [
    "### Fatorização de Matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f30e2",
   "metadata": {},
   "source": [
    "### Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9a3f7",
   "metadata": {},
   "source": [
    "### Modelagem de Classificação e Regressão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e003dd7",
   "metadata": {},
   "source": [
    "### Detecção de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9782fdd",
   "metadata": {},
   "source": [
    "## Otimização para Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f111d77",
   "metadata": {},
   "source": [
    "### Expansão de Taylor para Simplificação de Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38955ab",
   "metadata": {},
   "source": [
    "### Exemplos de Otimização em Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c648a",
   "metadata": {},
   "source": [
    "### Otimização em Grafos Computacionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1549781e",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e50dd",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb040afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c7c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cc00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2be66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef9fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbd3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d933c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f173c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d63e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275f5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7d909dc",
   "metadata": {},
   "source": [
    "- latexfy\n",
    "https://colab.research.google.com/drive/1MuiawKpVIZ12MWwyYuzZHmbKThdM5wNJ?usp=sharing#scrollTo=hViDMhyMFNCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a0f262",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T23:03:50.473250Z",
     "start_time": "2022-11-16T23:03:50.471609Z"
    }
   },
   "outputs": [],
   "source": [
    "# ocultar células"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.465px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
